{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee93f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pairs from ../data/processed/valid_pairs.csv...\n",
      "Found 121 pairs across 11 sectors.\n",
      "\n",
      "--- Processing Sector: communication_services (1 pairs) ---\n",
      "\n",
      "--- Processing Sector: consumer_discretionary (15 pairs) ---\n",
      "\n",
      "--- Processing Sector: consumer_staples (5 pairs) ---\n",
      "\n",
      "--- Processing Sector: energy (1 pairs) ---\n",
      "\n",
      "--- Processing Sector: financials (28 pairs) ---\n",
      "\n",
      "--- Processing Sector: health_care (3 pairs) ---\n",
      "\n",
      "--- Processing Sector: industrials (2 pairs) ---\n",
      "\n",
      "--- Processing Sector: information_technology (16 pairs) ---\n",
      "\n",
      "--- Processing Sector: materials (2 pairs) ---\n",
      "\n",
      "--- Processing Sector: tech (30 pairs) ---\n",
      "\n",
      "--- Processing Sector: utilities (18 pairs) ---\n",
      "\n",
      "SUCCESS! Generated dataset with shape: (113693, 8)\n",
      "Unique Pairs: 118\n",
      "Saved to ../data/processed/lstm_ready_data_multi.csv\n"
     ]
    }
   ],
   "source": [
    "#transform raw prices into a dataset ready cor Ridge/MLP/LSTM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "raw_dir = '../data/raw'\n",
    "pairs_path = '../data/processed/valid_pairs.csv' # Or 'valid_pairs_with_metrics.csv'\n",
    "output_path = '../data/processed/lstm_ready_data_multi.csv'\n",
    "\n",
    "# 1. LOAD PAIRS\n",
    "print(f\"Loading pairs from {pairs_path}...\")\n",
    "valid_pairs = pd.read_csv(pairs_path)\n",
    "\n",
    "# Check if 'Sector' column exists (it should from previous steps)\n",
    "if 'Sector' not in valid_pairs.columns:\n",
    "    print(\"Error: 'Sector' column missing in valid_pairs.csv. Cannot load correct prices.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found {len(valid_pairs)} pairs across {valid_pairs['Sector'].nunique()} sectors.\")\n",
    "\n",
    "all_pairs_data = []\n",
    "\n",
    "# 2. ITERATE BY SECTOR (Efficiency Boost)\n",
    "# Instead of loading prices 500 times, we load the sector file once and process all its pairs.\n",
    "grouped = valid_pairs.groupby('Sector')\n",
    "\n",
    "for sector_name, group in grouped:\n",
    "    print(f\"\\n--- Processing Sector: {sector_name} ({len(group)} pairs) ---\")\n",
    "    \n",
    "    # Dynamic Price Loading\n",
    "    price_file = f\"{sector_name}_prices.csv\"\n",
    "    price_path = os.path.join(raw_dir, price_file)\n",
    "    \n",
    "    try:\n",
    "        prices = pd.read_csv(price_path, index_col=0, parse_dates=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   Warning: Could not find price file {price_path}. Skipping sector.\")\n",
    "        continue\n",
    "\n",
    "    # Process each pair in this sector\n",
    "    for i, row in group.iterrows():\n",
    "        # --- FIX 1: Use Correct Column Names (Stock1 / Stock2) ---\n",
    "        stock_y = row['Stock1'] \n",
    "        stock_x = row['Stock2']\n",
    "        pair_name = f\"{stock_y}-{stock_x}\"\n",
    "        \n",
    "        # A. Get Prices & Clean\n",
    "        try:\n",
    "            Y = prices[stock_y]\n",
    "            X = prices[stock_x]\n",
    "        except KeyError:\n",
    "            print(f\"   Skipping {pair_name} (Ticker missing in price file)\")\n",
    "            continue\n",
    "\n",
    "        # Align dates (Inner Join)\n",
    "        df_pair = pd.concat([Y, X], axis=1).dropna()\n",
    "        if len(df_pair) < 200: # Skip if history is too short\n",
    "            continue\n",
    "            \n",
    "        Y, X = df_pair.iloc[:, 0], df_pair.iloc[:, 1]\n",
    "        \n",
    "        # B. Calculate Hedge Ratio (Rolling or Static)\n",
    "        # We use static here for simplicity, but rolling is better for production\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(Y, X_const).fit()\n",
    "        \n",
    "        # --- FIX 2: Robust Parameter Extraction ---\n",
    "        # Use .iloc[1] to get the slope, avoiding name mismatch errors\n",
    "        if len(model.params) < 2: continue\n",
    "        hedge_ratio = model.params.iloc[1]\n",
    "        \n",
    "        # C. Create Spread\n",
    "        spread = Y - (hedge_ratio * X)\n",
    "        \n",
    "        # D. Feature Engineering\n",
    "        df = pd.DataFrame(index=spread.index)\n",
    "        df['Spread'] = spread\n",
    "        \n",
    "        window = 20\n",
    "        # Z-Score\n",
    "        rolling_mean = df['Spread'].rolling(window).mean()\n",
    "        rolling_std = df['Spread'].rolling(window).std()\n",
    "        df['Z_Score'] = (df['Spread'] - rolling_mean) / rolling_std\n",
    "        \n",
    "        # Volatility\n",
    "        df['Volatility'] = df['Spread'].rolling(window).std()\n",
    "        \n",
    "        # Momentum (ROC)\n",
    "        df['Momentum'] = df['Spread'].diff(5)\n",
    "        \n",
    "        # TARGET GENERATION (The Answer Key)\n",
    "        # Did the spread go UP or DOWN tomorrow?\n",
    "        df['Future_Return'] = df['Spread'].shift(-1) - df['Spread']\n",
    "        df['Target_Direction'] = (df['Future_Return'] > 0).astype(int)\n",
    "        \n",
    "        # Metadata\n",
    "        df['Pair_ID'] = pair_name\n",
    "        df['Sector'] = sector_name\n",
    "        \n",
    "        # Drop NaNs created by rolling windows\n",
    "        all_pairs_data.append(df.dropna())\n",
    "\n",
    "# 3. COMBINE & SAVE\n",
    "if all_pairs_data:\n",
    "    giant_dataset = pd.concat(all_pairs_data)\n",
    "    print(f\"\\nSUCCESS! Generated dataset with shape: {giant_dataset.shape}\")\n",
    "    print(f\"Unique Pairs: {giant_dataset['Pair_ID'].nunique()}\")\n",
    "    \n",
    "    giant_dataset.to_csv(output_path)\n",
    "    print(f\"Saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No data generated. Check your input files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
