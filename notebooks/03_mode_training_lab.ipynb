{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed384dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py:2099\u001b[39m\n\u001b[32m   2095\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnable to find torch_shm_manager at \u001b[39m\u001b[33m\"\u001b[39m + path)\n\u001b[32m   2096\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m path.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2099\u001b[39m \u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[32m   2103\u001b[39m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[32m   2104\u001b[39m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[32m   2105\u001b[39m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[32m   2106\u001b[39m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\cuda\\__init__.py:30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gds\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_device_index\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     31\u001b[39m     CUDAGraph,\n\u001b[32m     32\u001b[39m     graph,\n\u001b[32m     33\u001b[39m     graph_pool_handle,\n\u001b[32m     34\u001b[39m     is_current_stream_capturing,\n\u001b[32m     35\u001b[39m     make_graphed_callables,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstreams\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Event, ExternalStream, Stream\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1023\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1119\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1218\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Link to src\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.models import BaselineModel, MLP, LSTMModel\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "df = pd.read_csv('../data/processed/lstm_ready_data_multi.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "feature_cols = ['Z_Score', 'Volatility', 'Momentum'] # Must match your CSV columns\n",
    "X = df[feature_cols].values\n",
    "y = df['Target_Direction'].values\n",
    "\n",
    "# --- 2. PREPARE DATA (Normalize) ---\n",
    "# Neural Networks require data to be centered around 0\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. HELPER: CREATE SEQUENCES FOR LSTM ---\n",
    "def create_sequences(data, target, lookback=10):\n",
    "    \"\"\"\n",
    "    Converts 2D data into 3D sequences for LSTM.\n",
    "    Input: (1000, 3) -> Output: (990, 10, 3)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X_seq.append(data[i:i+lookback]) # The sequence (Days t-10 to t)\n",
    "        y_seq.append(target[i+lookback]) # The target (Day t+1)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create 3D data for Tier 3\n",
    "LOOKBACK = 10\n",
    "X_lstm, y_lstm = create_sequences(X_scaled, y, lookback=LOOKBACK)\n",
    "\n",
    "# Align 2D data for Tier 1 & 2 (must match LSTM length to be fair)\n",
    "X_flat = X_scaled[LOOKBACK:]\n",
    "y_flat = y[LOOKBACK:]\n",
    "\n",
    "# --- 4. TRAIN/TEST SPLIT (No Random Shuffling!) ---\n",
    "# We split by time. Train on 2020-2023, Test on 2024.\n",
    "split = int(len(X_flat) * 0.8)\n",
    "\n",
    "# Data for Tier 1 & 2\n",
    "X_train_2d, X_test_2d = X_flat[:split], X_flat[split:]\n",
    "y_train, y_test = y_flat[:split], y_flat[split:]\n",
    "\n",
    "# Data for Tier 3 (LSTM)\n",
    "X_train_3d, X_test_3d = X_lstm[:split], X_lstm[split:]\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_tensor_2d = torch.FloatTensor(X_train_2d)\n",
    "X_test_tensor_2d = torch.FloatTensor(X_test_2d)\n",
    "X_train_tensor_3d = torch.FloatTensor(X_train_3d)\n",
    "X_test_tensor_3d = torch.FloatTensor(X_test_3d)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "\n",
    "print(f\"Training Data Shape (2D): {X_train_2d.shape}\")\n",
    "print(f\"Training Data Shape (3D): {X_train_3d.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 1: RIDGE REGRESSION (Baseline)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 1: Ridge Regression ---\")\n",
    "model_ridge = BaselineModel(alpha=1.0)\n",
    "model_ridge.fit(X_train_2d, y_train)\n",
    "pred_ridge = model_ridge.predict(X_test_2d)\n",
    "acc_ridge = accuracy_score(y_test, pred_ridge)\n",
    "print(f\"Tier 1 Accuracy: {acc_ridge:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 2: MLP (Classical ML)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 2: MLP ---\")\n",
    "model_mlp = MLP(input_dim=3)\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_mlp(X_train_tensor_2d)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    pred_mlp_prob = model_mlp(X_test_tensor_2d)\n",
    "    pred_mlp = (pred_mlp_prob > 0.5).float().numpy().flatten()\n",
    "    \n",
    "acc_mlp = accuracy_score(y_test, pred_mlp)\n",
    "print(f\"Tier 2 Accuracy: {acc_mlp:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 3: LSTM (Deep Learning)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 3: LSTM ---\")\n",
    "model_lstm = LSTMModel(input_dim=3, hidden_dim=64)\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_lstm(X_train_tensor_3d) # Feeding 3D Data!\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    pred_lstm_prob = model_lstm(X_test_tensor_3d)\n",
    "    pred_lstm = (pred_lstm_prob > 0.5).float().numpy().flatten()\n",
    "\n",
    "acc_lstm = accuracy_score(y_test, pred_lstm)\n",
    "print(f\"Tier 3 Accuracy: {acc_lstm:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# FINAL REPORT\n",
    "# ==========================================\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Ridge (Baseline)', 'MLP (Non-Linear)', 'LSTM (Sequential)'],\n",
    "    'Accuracy': [acc_ridge, acc_mlp, acc_lstm]\n",
    "})\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27a694",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n",
      "\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py:2099\u001b[39m\n",
      "\u001b[32m   2095\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnable to find torch_shm_manager at \u001b[39m\u001b[33m\"\u001b[39m + path)\n",
      "\u001b[32m   2096\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m path.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2099\u001b[39m \u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n",
      "\u001b[32m   2103\u001b[39m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n",
      "\u001b[32m   2104\u001b[39m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n",
      "\u001b[32m   2105\u001b[39m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n",
      "\u001b[32m   2106\u001b[39m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\cuda\\__init__.py:30\u001b[39m\n",
      "\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gds\n",
      "\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_device_index\n",
      "\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[32m     31\u001b[39m     CUDAGraph,\n",
      "\u001b[32m     32\u001b[39m     graph,\n",
      "\u001b[32m     33\u001b[39m     graph_pool_handle,\n",
      "\u001b[32m     34\u001b[39m     is_current_stream_capturing,\n",
      "\u001b[32m     35\u001b[39m     make_graphed_callables,\n",
      "\u001b[32m     36\u001b[39m )\n",
      "\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstreams\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Event, ExternalStream, Stream\n",
      "\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1023\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1119\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1218\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Link to src\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.models import BaselineModel, MLP, LSTMModel\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "df = pd.read_csv('../data/processed/lstm_ready_data_multi.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "feature_cols = ['Z_Score', 'Volatility', 'Momentum'] # Must match your CSV columns\n",
    "X = df[feature_cols].values\n",
    "y = df['Target_Direction'].values\n",
    "\n",
    "# --- 2. PREPARE DATA (Normalize) ---\n",
    "# Neural Networks require data to be centered around 0\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. HELPER: CREATE SEQUENCES FOR LSTM ---\n",
    "def create_sequences(data, target, lookback=10):\n",
    "    \"\"\"\n",
    "    Converts 2D data into 3D sequences for LSTM.\n",
    "    Input: (1000, 3) -> Output: (990, 10, 3)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X_seq.append(data[i:i+lookback]) # The sequence (Days t-10 to t)\n",
    "        y_seq.append(target[i+lookback]) # The target (Day t+1)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create 3D data for Tier 3\n",
    "LOOKBACK = 10\n",
    "X_lstm, y_lstm = create_sequences(X_scaled, y, lookback=LOOKBACK)\n",
    "\n",
    "# Align 2D data for Tier 1 & 2 (must match LSTM length to be fair)\n",
    "X_flat = X_scaled[LOOKBACK:]\n",
    "y_flat = y[LOOKBACK:]\n",
    "\n",
    "# --- 4. TRAIN/TEST SPLIT (No Random Shuffling!) ---\n",
    "# We split by time. Train on 2020-2023, Test on 2024.\n",
    "split = int(len(X_flat) * 0.8)\n",
    "\n",
    "# Data for Tier 1 & 2\n",
    "X_train_2d, X_test_2d = X_flat[:split], X_flat[split:]\n",
    "y_train, y_test = y_flat[:split], y_flat[split:]\n",
    "\n",
    "# Data for Tier 3 (LSTM)\n",
    "X_train_3d, X_test_3d = X_lstm[:split], X_lstm[split:]\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_tensor_2d = torch.FloatTensor(X_train_2d)\n",
    "X_test_tensor_2d = torch.FloatTensor(X_test_2d)\n",
    "X_train_tensor_3d = torch.FloatTensor(X_train_3d)\n",
    "X_test_tensor_3d = torch.FloatTensor(X_test_3d)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "\n",
    "print(f\"Training Data Shape (2D): {X_train_2d.shape}\")\n",
    "print(f\"Training Data Shape (3D): {X_train_3d.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 1: RIDGE REGRESSION (Baseline)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 1: Ridge Regression ---\")\n",
    "model_ridge = BaselineModel(alpha=1.0)\n",
    "model_ridge.fit(X_train_2d, y_train)\n",
    "pred_ridge = model_ridge.predict(X_test_2d)\n",
    "acc_ridge = accuracy_score(y_test, pred_ridge)\n",
    "print(f\"Tier 1 Accuracy: {acc_ridge:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 2: MLP (Classical ML)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 2: MLP ---\")\n",
    "model_mlp = MLP(input_dim=3)\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_mlp(X_train_tensor_2d)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    pred_mlp_prob = model_mlp(X_test_tensor_2d)\n",
    "    pred_mlp = (pred_mlp_prob > 0.5).float().numpy().flatten()\n",
    "    \n",
    "acc_mlp = accuracy_score(y_test, pred_mlp)\n",
    "print(f\"Tier 2 Accuracy: {acc_mlp:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# TIER 3: LSTM (Deep Learning)\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Tier 3: LSTM ---\")\n",
    "model_lstm = LSTMModel(input_dim=3, hidden_dim=64)\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_lstm(X_train_tensor_3d) # Feeding 3D Data!\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    pred_lstm_prob = model_lstm(X_test_tensor_3d)\n",
    "    pred_lstm = (pred_lstm_prob > 0.5).float().numpy().flatten()\n",
    "\n",
    "acc_lstm = accuracy_score(y_test, pred_lstm)\n",
    "print(f\"Tier 3 Accuracy: {acc_lstm:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# FINAL REPORT\n",
    "# ==========================================\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Ridge (Baseline)', 'MLP (Non-Linear)', 'LSTM (Sequential)'],\n",
    "    'Accuracy': [acc_ridge, acc_mlp, acc_lstm]\n",
    "})\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aea491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
