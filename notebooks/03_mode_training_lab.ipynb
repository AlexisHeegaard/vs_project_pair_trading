{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed384dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING ON ALL 5 PAIRS: Jan 2021 - Dec 2023\n",
      "TESTING ON: Jan 2024 - Dec 2025\n",
      "================================================================================\n",
      "\n",
      "üì• Loading data...\n",
      "   Total rows: 5223\n",
      "   Date range: 2021-02-02 to 2025-12-29\n",
      "   Unique pairs: 5\n",
      "\n",
      "üìÖ Date-based train/test split:\n",
      "   TRAIN: 2021-02-02 to 2023-12-31\n",
      "   TEST:  2024-01-01 to 2025-12-29\n",
      "\n",
      "   Train samples: 2843\n",
      "   Test samples: 2380\n",
      "\n",
      "   Train breakdown by pair:\n",
      "      ADSK-MSI: 482\n",
      "      ADSK-NOW: 482\n",
      "      AIG-CB: 664\n",
      "      CMS-DUK: 733\n",
      "      INTU-MSFT: 482\n",
      "\n",
      "   Test breakdown by pair:\n",
      "      ADSK-MSI: 460\n",
      "      ADSK-NOW: 460\n",
      "      AIG-CB: 500\n",
      "      CMS-DUK: 500\n",
      "      INTU-MSFT: 460\n",
      "\n",
      "üîÑ Preparing features...\n",
      "\n",
      "üìä Generating training sequences (Lookback=10)...\n",
      "   X_train_3d shape: (2793, 10, 2)\n",
      "   X_train_2d shape: (2793, 2)\n",
      "   y_train shape: (2793,)\n",
      "\n",
      "üìä Generating test sequences (Lookback=10)...\n",
      "   X_test_3d shape: (2330, 10, 2)\n",
      "   X_test_2d shape: (2330, 2)\n",
      "   y_test shape: (2330,)\n",
      "\n",
      "üìà Target distribution:\n",
      "   Train: 1394 down, 1399 up (50.1% up)\n",
      "   Test:  1157 down, 1173 up (50.3% up)\n",
      "\n",
      "üîß Converting to PyTorch tensors...\n",
      "\n",
      "================================================================================\n",
      "TRAINING MODELS\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Training Ridge Regression...\n",
      "   ‚úÖ Complete\n",
      "\n",
      "2Ô∏è‚É£  Training LSTM...\n",
      "      Epoch 20/100 - Loss: 0.692399\n",
      "      Epoch 40/100 - Loss: 0.691521\n",
      "      Epoch 60/100 - Loss: 0.690673\n",
      "      Epoch 80/100 - Loss: 0.689090\n",
      "      Epoch 100/100 - Loss: 0.685938\n",
      "   ‚úÖ Complete\n",
      "\n",
      "================================================================================\n",
      "GENERATING PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "   Ridge predictions...\n",
      "   LSTM predictions...\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SUCCESS!\n",
      "================================================================================\n",
      "\n",
      "üìä Results saved to: ../data/processed/05_model_predictions.csv\n",
      "   Shape: (2330, 9)\n",
      "   Date range: 2024-01-17 to 2025-12-29\n",
      "   Columns: ['Spread', 'Z_Score', 'Volatility', 'Target_Return', 'Target_Direction', 'Pair_ID', 'Sector', 'Ridge_Pred', 'LSTM_Pred']\n",
      "\n",
      "   Pair breakdown in predictions:\n",
      "      ADSK-MSI: 450 predictions\n",
      "      ADSK-NOW: 450 predictions\n",
      "      AIG-CB: 490 predictions\n",
      "      CMS-DUK: 490 predictions\n",
      "      INTU-MSFT: 450 predictions\n",
      "\n",
      "================================================================================\n",
      "QUICK PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Ridge:\n",
      "   Accuracy:  0.5112\n",
      "   Precision: 0.5151\n",
      "   Recall:    0.4953\n",
      "   F1 Score:  0.5050\n",
      "\n",
      "LSTM:\n",
      "   Accuracy:  0.5082\n",
      "   Precision: 0.5106\n",
      "   Recall:    0.5558\n",
      "   F1 Score:  0.5322\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE BY PAIR\n",
      "================================================================================\n",
      "\n",
      "ADSK-MSI (450 samples):\n",
      "   Ridge: 0.4911 | LSTM: 0.5067\n",
      "\n",
      "ADSK-NOW (450 samples):\n",
      "   Ridge: 0.5067 | LSTM: 0.5111\n",
      "\n",
      "AIG-CB (490 samples):\n",
      "   Ridge: 0.5184 | LSTM: 0.5082\n",
      "\n",
      "CMS-DUK (490 samples):\n",
      "   Ridge: 0.5041 | LSTM: 0.4980\n",
      "\n",
      "INTU-MSFT (450 samples):\n",
      "   Ridge: 0.5356 | LSTM: 0.5178\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE BY SECTOR\n",
      "================================================================================\n",
      "\n",
      "FINANCIALS (490 samples):\n",
      "   Ridge: 0.5184 | LSTM: 0.5082\n",
      "\n",
      "TECH (1350 samples):\n",
      "   Ridge: 0.5111 | LSTM: 0.5119\n",
      "\n",
      "UTILITIES (490 samples):\n",
      "   Ridge: 0.5041 | LSTM: 0.4980\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Training and predictions complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Link to your src/models.py\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.models import BaselineModel, LSTMModel\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING ON ALL 5 PAIRS: Jan 2021 - Dec 2023\")\n",
    "print(\"TESTING ON: Jan 2024 - Dec 2025\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. DATA LOADING\n",
    "print(\"\\nüì• Loading data...\")\n",
    "df = pd.read_csv('../data/processed/04_ml_ready_features.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"   Total rows: {len(df)}\")\n",
    "print(f\"   Date range: {df.index.min().date()} to {df.index.max().date()}\")\n",
    "print(f\"   Unique pairs: {df['Pair_ID'].nunique()}\")\n",
    "\n",
    "# 2. DATE-BASED SPLIT (not random 80/20)\n",
    "train_end = '2023-12-31'\n",
    "\n",
    "print(f\"\\nüìÖ Date-based train/test split:\")\n",
    "print(f\"   TRAIN: {df.index.min().date()} to {pd.to_datetime(train_end).date()}\")\n",
    "print(f\"   TEST:  {(pd.to_datetime(train_end) + pd.Timedelta(days=1)).date()} to {df.index.max().date()}\")\n",
    "\n",
    "df_train_full = df[df.index <= train_end].copy()\n",
    "df_test_full = df[df.index > train_end].copy()\n",
    "\n",
    "print(f\"\\n   Train samples: {len(df_train_full)}\")\n",
    "print(f\"   Test samples: {len(df_test_full)}\")\n",
    "\n",
    "print(f\"\\n   Train breakdown by pair:\")\n",
    "for pair in sorted(df_train_full['Pair_ID'].unique()):\n",
    "    count = (df_train_full['Pair_ID'] == pair).sum()\n",
    "    print(f\"      {pair}: {count}\")\n",
    "\n",
    "print(f\"\\n   Test breakdown by pair:\")\n",
    "for pair in sorted(df_test_full['Pair_ID'].unique()):\n",
    "    count = (df_test_full['Pair_ID'] == pair).sum()\n",
    "    print(f\"      {pair}: {count}\")\n",
    "\n",
    "# 3. PREPARE FEATURES WITH PROPER SCALING (NO DATA LEAKAGE)\n",
    "print(f\"\\nüîÑ Preparing features...\")\n",
    "\n",
    "feature_cols = ['Z_Score', 'Volatility']\n",
    "\n",
    "# Fit scaler ONLY on training data (prevent data leakage)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_vals = scaler.fit_transform(df_train_full[feature_cols])\n",
    "\n",
    "# Create scaled dataframe for training\n",
    "df_train_scaled = pd.DataFrame(X_train_scaled_vals, columns=feature_cols, index=df_train_full.index)\n",
    "df_train_scaled['Target'] = df_train_full['Target_Direction'].values\n",
    "df_train_scaled['Pair_ID'] = df_train_full['Pair_ID'].values\n",
    "df_train_scaled['DateTime'] = df_train_full.index\n",
    "df_train_scaled['Original_Index'] = np.arange(len(df_train_full))\n",
    "\n",
    "# Apply same scaler to test data\n",
    "X_test_scaled_vals = scaler.transform(df_test_full[feature_cols])\n",
    "\n",
    "# Create scaled dataframe for testing\n",
    "df_test_scaled = pd.DataFrame(X_test_scaled_vals, columns=feature_cols, index=df_test_full.index)\n",
    "df_test_scaled['Target'] = df_test_full['Target_Direction'].values\n",
    "df_test_scaled['Pair_ID'] = df_test_full['Pair_ID'].values\n",
    "df_test_scaled['DateTime'] = df_test_full.index\n",
    "df_test_scaled['Original_Index'] = np.arange(len(df_test_full))\n",
    "\n",
    "# 4. PAIR-AWARE SEQUENCE GENERATION\n",
    "def create_pair_sequences(data_df, lookback=10):\n",
    "    \"\"\"Generate sequences per pair to maintain trading logic\"\"\"\n",
    "    X_seq, y_seq, indices = [], [], []\n",
    "    \n",
    "    for pair in data_df['Pair_ID'].unique():\n",
    "        pair_df = data_df[data_df['Pair_ID'] == pair].reset_index(drop=True)\n",
    "        X_vals = pair_df[feature_cols].values\n",
    "        y_vals = pair_df['Target'].values\n",
    "        row_ids = pair_df['Original_Index'].values \n",
    "        \n",
    "        if len(X_vals) <= lookback: \n",
    "            continue\n",
    "        \n",
    "        for i in range(len(X_vals) - lookback):\n",
    "            X_seq.append(X_vals[i:i+lookback])\n",
    "            y_seq.append(y_vals[i+lookback])\n",
    "            indices.append(row_ids[i+lookback]) \n",
    "            \n",
    "    return np.array(X_seq), np.array(y_seq), np.array(indices)\n",
    "\n",
    "LOOKBACK = 10\n",
    "print(f\"\\nüìä Generating training sequences (Lookback={LOOKBACK})...\")\n",
    "X_train_3d, y_train, train_indices = create_pair_sequences(df_train_scaled, lookback=LOOKBACK)\n",
    "X_train_2d = np.array([s[-1] for s in X_train_3d])\n",
    "\n",
    "print(f\"   X_train_3d shape: {X_train_3d.shape}\")\n",
    "print(f\"   X_train_2d shape: {X_train_2d.shape}\")\n",
    "print(f\"   y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"\\nüìä Generating test sequences (Lookback={LOOKBACK})...\")\n",
    "X_test_3d, y_test, test_indices = create_pair_sequences(df_test_scaled, lookback=LOOKBACK)\n",
    "X_test_2d = np.array([s[-1] for s in X_test_3d])\n",
    "\n",
    "print(f\"   X_test_3d shape: {X_test_3d.shape}\")\n",
    "print(f\"   X_test_2d shape: {X_test_2d.shape}\")\n",
    "print(f\"   y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 5. CLASS DISTRIBUTION\n",
    "print(f\"\\nüìà Target distribution:\")\n",
    "print(f\"   Train: {(y_train == 0).sum()} down, {(y_train == 1).sum()} up ({100*y_train.mean():.1f}% up)\")\n",
    "print(f\"   Test:  {(y_test == 0).sum()} down, {(y_test == 1).sum()} up ({100*y_test.mean():.1f}% up)\")\n",
    "\n",
    "# 6. CONVERT TO TENSORS (for LSTM)\n",
    "print(f\"\\nüîß Converting to PyTorch tensors...\")\n",
    "X_train_t3d = torch.FloatTensor(X_train_3d)\n",
    "X_test_t3d = torch.FloatTensor(X_test_3d)\n",
    "y_train_t = torch.FloatTensor(y_train).view(-1, 1)\n",
    "\n",
    "# 7. TRAINING FUNCTION\n",
    "def train_torch_model(model, X_train, y_train_t, epochs=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"      Epoch {epoch+1}/{epochs} - Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 8. TRAIN ALL MODELS\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING MODELS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  Training Ridge Regression...\")\n",
    "model_ridge = BaselineModel(alpha=1.0)\n",
    "model_ridge.fit(X_train_2d, y_train)\n",
    "print(f\"   ‚úÖ Complete\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  Training LSTM...\")\n",
    "model_lstm = LSTMModel(input_dim=2)\n",
    "model_lstm = train_torch_model(model_lstm, X_train_t3d, y_train_t, epochs=100)\n",
    "print(f\"   ‚úÖ Complete\")\n",
    "\n",
    "# 9. GENERATE & SAVE PREDICTIONS FOR ALL MODELS\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Map test indices back to original dataframe\n",
    "test_results = df_test_full.iloc[test_indices].copy()\n",
    "\n",
    "# Set DateTime as index\n",
    "test_results['DateTime'] = pd.to_datetime(test_results.index)\n",
    "test_results = test_results.set_index('DateTime')\n",
    "\n",
    "# Generate Predictions for Each Model\n",
    "print(\"   Ridge predictions...\")\n",
    "ridge_preds = model_ridge.predict(X_test_2d)\n",
    "test_results['Ridge_Pred'] = ridge_preds\n",
    "\n",
    "print(\"   LSTM predictions...\")\n",
    "with torch.no_grad():\n",
    "    model_lstm.eval()\n",
    "    lstm_preds = model_lstm(X_test_t3d).numpy().flatten()\n",
    "test_results['LSTM_Pred'] = lstm_preds\n",
    "\n",
    "# Sort by date\n",
    "test_results = test_results.sort_index()\n",
    "\n",
    "# Save to CSV\n",
    "output_file = '../data/processed/05_model_predictions.csv'\n",
    "test_results.to_csv(output_file)\n",
    "\n",
    "# 10. RESULTS SUMMARY\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ SUCCESS!\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nüìä Results saved to: {output_file}\")\n",
    "print(f\"   Shape: {test_results.shape}\")\n",
    "print(f\"   Date range: {test_results.index.min().date()} to {test_results.index.max().date()}\")\n",
    "print(f\"   Columns: {test_results.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\n   Pair breakdown in predictions:\")\n",
    "for pair in sorted(test_results['Pair_ID'].unique()):\n",
    "    count = (test_results['Pair_ID'] == pair).sum()\n",
    "    print(f\"      {pair}: {count} predictions\")\n",
    "\n",
    "# 11. QUICK PERFORMANCE SUMMARY\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"QUICK PERFORMANCE SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "y_test_true = test_results['Target_Direction'].values\n",
    "\n",
    "for model_name, preds in [('Ridge', ridge_preds), ('LSTM', lstm_preds)]:\n",
    "    # Convert to binary\n",
    "    if model_name == 'Ridge':\n",
    "        preds_binary = preds  # Already binary\n",
    "    else:\n",
    "        preds_binary = (preds >= 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test_true, preds_binary)\n",
    "    prec = precision_score(y_test_true, preds_binary, zero_division=0)\n",
    "    rec = recall_score(y_test_true, preds_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test_true, preds_binary, zero_division=0)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1 Score:  {f1:.4f}\\n\")\n",
    "\n",
    "# 12. PER-PAIR PERFORMANCE\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE BY PAIR\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for pair in sorted(test_results['Pair_ID'].unique()):\n",
    "    pair_mask = test_results['Pair_ID'] == pair\n",
    "    y_pair = y_test_true[pair_mask]\n",
    "    n = pair_mask.sum()\n",
    "    \n",
    "    ridge_binary = ridge_preds[pair_mask]\n",
    "    lstm_binary = (lstm_preds[pair_mask] >= 0.5).astype(int)\n",
    "    \n",
    "    ridge_acc = accuracy_score(y_pair, ridge_binary)\n",
    "    lstm_acc = accuracy_score(y_pair, lstm_binary)\n",
    "    \n",
    "    print(f\"{pair} ({n} samples):\")\n",
    "    print(f\"   Ridge: {ridge_acc:.4f} | LSTM: {lstm_acc:.4f}\\n\")\n",
    "\n",
    "# 13. SECTOR PERFORMANCE\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PERFORMANCE BY SECTOR\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for sector in sorted(test_results['Sector'].unique()):\n",
    "    sector_mask = test_results['Sector'] == sector\n",
    "    y_sector = y_test_true[sector_mask]\n",
    "    n = sector_mask.sum()\n",
    "    \n",
    "    ridge_binary = ridge_preds[sector_mask]\n",
    "    lstm_binary = (lstm_preds[sector_mask] >= 0.5).astype(int)\n",
    "    \n",
    "    ridge_acc = accuracy_score(y_sector, ridge_binary)\n",
    "    lstm_acc = accuracy_score(y_sector, lstm_binary)\n",
    "    \n",
    "    print(f\"{sector.upper()} ({n} samples):\")\n",
    "    print(f\"   Ridge: {ridge_acc:.4f} | LSTM: {lstm_acc:.4f}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"‚úÖ Training and predictions complete!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27a694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aea491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
