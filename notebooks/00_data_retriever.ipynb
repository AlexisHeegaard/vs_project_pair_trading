{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a902dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading tickers from cache: ../data/raw/sp500_tickers.csv\n",
      "\n",
      "Ready to process 11 sectors.\n",
      "Sample: ['Communication Services', 'Consumer Discretionary', 'Consumer Staples']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# DATA DIRECTORY CONFIGURATION \n",
    "DATA_DIR = '../data/raw'\n",
    "CACHE_FILE = f'{DATA_DIR}/sp500_tickers.csv'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def get_sp500_tickers():\n",
    "    \n",
    "    #Fetches S&P 500 tickers from Wikipedia\n",
    "    #If the file exists locally, it loads it. If not, it scrapes.\n",
    "    \n",
    "    # 1. CHECK CACHE\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        print(f\"✅ Loading tickers from cache: {CACHE_FILE}\")\n",
    "        return pd.read_csv(CACHE_FILE)\n",
    "\n",
    "    # 2. SCRAPE WIKIPEDIA (If cache missing)\n",
    "    print(\"⚠️ Cache not found. Scraping Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        tables = pd.read_html(r.text)\n",
    "        \n",
    "        # Robust Table Search: Find the one with \"GICS Sector\"\n",
    "        sp500_table = next((t for t in tables if \"GICS Sector\" in t.columns), None)\n",
    "        \n",
    "        if sp500_table is None:\n",
    "            raise ValueError(\"Could not find S&P 500 table.\")\n",
    "\n",
    "        # 3. CLEAN SYMBOLS\n",
    "        # Yahoo Finance uses '-' instead of '.' (e.g., BRK.B -> BRK-B)\n",
    "        sp500_table['Symbol'] = sp500_table['Symbol'].str.replace('.', '-', regex=False)\n",
    "        \n",
    "        # 4. SAVE TO CACHE\n",
    "        sp500_table.to_csv(CACHE_FILE, index=False)\n",
    "        print(f\"✅ Scraped and saved {len(sp500_table)} tickers to {CACHE_FILE}\")\n",
    "        return sp500_table\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error scraping: {e}\")\n",
    "        # Fallback list just in case\n",
    "        return pd.DataFrame({\n",
    "            'Symbol': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA'], \n",
    "            'GICS Sector': ['Information Technology']*5\n",
    "        })\n",
    "\n",
    "# EXECUTION \n",
    "df_tickers = get_sp500_tickers()\n",
    "\n",
    "# group tickers by each corresponding GICS sector in order to creat a dataframe for each sector\n",
    "tickers_by_sector = df_tickers.groupby('GICS Sector')['Symbol'].apply(list).to_dict()\n",
    "\n",
    "print(f\"\\nReady to process {len(tickers_by_sector)} sectors.\")\n",
    "print(f\"Sample: {list(tickers_by_sector.keys())[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93f0884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for 11 sectors...\n",
      "\n",
      " Processing Sector: Communication Services \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  23 of 23 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 23 stocks\n",
      "  Volume Threshold: 2165402 avg shares/day\n",
      "  Dropping 6 low-volume stocks...\n",
      "  Final Shape: (1253, 17)\n",
      "  Saved -> communication_services\n",
      "\n",
      " Processing Sector: Consumer Discretionary \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  49 of 49 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 49 stocks\n",
      "  Volume Threshold: 1784052 avg shares/day\n",
      "  Dropping 12 low-volume stocks...\n",
      "  Final Shape: (1253, 37)\n",
      "  Saved -> consumer_discretionary\n",
      "\n",
      " Processing Sector: Consumer Staples \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  37 of 37 completed\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_37848\\982927799.py:67: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  sector_returns = df_close.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 37 stocks\n",
      "  Volume Threshold: 1954203 avg shares/day\n",
      "  Dropping 9 low-volume stocks...\n",
      "  Final Shape: (1253, 27)\n",
      "  Saved -> consumer_staples\n",
      "\n",
      " Processing Sector: Energy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  22 of 22 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 22 stocks\n",
      "  Volume Threshold: 3299652 avg shares/day\n",
      "  Dropping 6 low-volume stocks...\n",
      "  Final Shape: (1253, 16)\n",
      "  Saved -> energy\n",
      "\n",
      " Processing Sector: Financials \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  75 of 75 completed\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_37848\\982927799.py:67: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  sector_returns = df_close.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 75 stocks\n",
      "  Volume Threshold: 1176838 avg shares/day\n",
      "  Dropping 19 low-volume stocks...\n",
      "  Final Shape: (1184, 55)\n",
      "  Saved -> financials\n",
      "\n",
      " Processing Sector: Health Care \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  60 of 60 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 60 stocks\n",
      "  Volume Threshold: 925519 avg shares/day\n",
      "  Dropping 15 low-volume stocks...\n",
      "  Final Shape: (1253, 43)\n",
      "  Saved -> health_care\n",
      "\n",
      " Processing Sector: Industrials \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  79 of 79 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 79 stocks\n",
      "  Volume Threshold: 899898 avg shares/day\n",
      "  Dropping 20 low-volume stocks...\n",
      "  Final Shape: (1253, 57)\n",
      "  Saved -> industrials\n",
      "\n",
      " Processing Sector: Information Technology \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  70 of 70 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 70 stocks\n",
      "  Volume Threshold: 1375267 avg shares/day\n",
      "  Dropping 18 low-volume stocks...\n",
      "  Final Shape: (1183, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved -> information_technology\n",
      "\n",
      " Processing Sector: Materials \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  26 of 26 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 26 stocks\n",
      "  Volume Threshold: 1405787 avg shares/day\n",
      "  Dropping 7 low-volume stocks...\n",
      "  Final Shape: (1253, 18)\n",
      "  Saved -> materials\n",
      "\n",
      " Processing Sector: Real Estate \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  31 of 31 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 31 stocks\n",
      "  Volume Threshold: 963515 avg shares/day\n",
      "  Dropping 8 low-volume stocks...\n",
      "  Final Shape: (1253, 23)\n",
      "  Saved -> real_estate\n",
      "\n",
      " Processing Sector: Utilities \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  31 of 31 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Initial count: 31 stocks\n",
      "  Volume Threshold: 1927416 avg shares/day\n",
      "  Dropping 8 low-volume stocks...\n",
      "  Final Shape: (1253, 22)\n",
      "  Saved -> utilities\n",
      "\n",
      "All sectors processed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#DATA DOWNLOADER AND PROCESSOR\n",
    "#turn tickers list into price and returns dataframes for each sector\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(f\"Starting download for {len(tickers_by_sector)} sectors...\")\n",
    "\n",
    "for sector_name, sector_tickers in tickers_by_sector.items():\n",
    "    # Clean sector name for filename (remove spaces/special chars)\n",
    "    safe_sector_name = sector_name.replace(\" \", \"_\").lower()\n",
    "    print(f\"\\n Processing Sector: {sector_name} \")\n",
    "    \n",
    "    # Download both Closing price and Volume data\n",
    "    # We create a list of tickers to ensure yfinance treats it as a batch\n",
    "    try:\n",
    "        raw_data = yf.download(\n",
    "            list(sector_tickers), \n",
    "            start=\"2021-01-01\", \n",
    "            end=\"2025-12-31\", \n",
    "            auto_adjust=True, \n",
    "            threads=True,\n",
    "            group_by='column' # Helps structure the multi-index\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {sector_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if data is empty\n",
    "    if raw_data.empty:\n",
    "        print(f\"No data found for {sector_name}\")\n",
    "        continue\n",
    "\n",
    "    # Extract Closing price and Volume frames\n",
    "    try:\n",
    "        df_close = raw_data['Close']\n",
    "        df_volume = raw_data['Volume']\n",
    "    except KeyError:\n",
    "        print(f\"Data structure error for {sector_name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(f\"  Initial count: {df_close.shape[1]} stocks\")\n",
    "    \n",
    "    # Filter by Volume - LIQUIDITY CHECK\n",
    "    # Calculate average daily volume for each stock\n",
    "    avg_volume = df_volume.mean()\n",
    "    \n",
    "    # Define the volume Threshold: Drop the bottom 25% (lowest liquidity stocks)\n",
    "    volume_threshold = avg_volume.quantile(0.25) \n",
    "    \n",
    "    # Identify liquid tickers\n",
    "    liquid_tickers = avg_volume[avg_volume >= volume_threshold].index\n",
    "    \n",
    "    print(f\"  Volume Threshold: {volume_threshold:.0f} avg shares/day\")\n",
    "    print(f\"  Dropping {len(sector_tickers) - len(liquid_tickers)} low-volume stocks...\")\n",
    "    \n",
    "    # Keep only liquid stocks in the price dataframe\n",
    "    df_close = df_close[liquid_tickers]\n",
    "\n",
    "    # 3. Handle Missing Data\n",
    "    # First, drop columns that are entirely NaN\n",
    "    df_close = df_close.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Calculate returns to check for data validity\n",
    "    sector_returns = df_close.pct_change()\n",
    "    \n",
    "    # Filter: Keep stocks with at least 90% valid data points\n",
    "    min_data_points = 0.9 * len(sector_returns)\n",
    "    sector_returns = sector_returns.dropna(thresh=min_data_points, axis=1)\n",
    "    \n",
    "    # Forward fill prices/returns to handle small gaps, then drop remaining NaNs\n",
    "    sector_returns = sector_returns.ffill().dropna()\n",
    "    \n",
    "    # Re-align prices to match the final cleaned returns columns\n",
    "    final_prices = df_close[sector_returns.columns].loc[sector_returns.index]\n",
    "\n",
    "    print(f\"  Final Shape: {final_prices.shape}\")\n",
    "\n",
    "    # 4. Save Data\n",
    "    # Save Prices\n",
    "    price_filename = f'../data/raw/{safe_sector_name}_prices.csv'\n",
    "    final_prices.to_csv(price_filename)\n",
    "    \n",
    "    # Save Returns (for PCA/Clustering)\n",
    "    returns_filename = f'../data/processed/{safe_sector_name}_returns.csv'\n",
    "    sector_returns.to_csv(returns_filename)\n",
    "    \n",
    "    print(f\"  Saved -> {safe_sector_name}\")\n",
    "\n",
    "print(\"\\nAll sectors processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9848540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
